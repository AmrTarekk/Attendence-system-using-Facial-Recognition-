{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have one face !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceOrNot(img) :\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    #print(faces)\n",
    "    if len(faces) == 1 :\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Model Calling\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer\n",
    "from model import create_model\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn4_small2_pretrained = create_model()\n",
    "nn4_small2_pretrained.load_weights('weights/nn4.small2.v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Preprocessing\n",
    "import cv2\n",
    "from align import AlignDlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    #print(img)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "\n",
    "# Initialize the OpenFace face alignment utility\n",
    "alignment = AlignDlib('landmarks.dat')\n",
    "\n",
    "def align_image(img):\n",
    "    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), \n",
    "                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of list of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListOfVec(ID) : \n",
    "    Resultlist = []\n",
    "    for i in range(5) :\n",
    "        path = \"images/\" + str(ID) + \"/opencv_frame_\" + str(i+1) + \".jpg\"\n",
    "        #print(path)\n",
    "        img = load_image(path)\n",
    "        img = align_image(img)\n",
    "        #img = (img / 255.).astype(np.float32)\n",
    "        Resultlist.append(nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0])\n",
    "        #print(len(Resultlist))\n",
    "    return Resultlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw our real product we will be fetching vectors from our csv file but for now 'Testing phase' \n",
    "#we will extract our vectors using our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VecList1 = np.zeros((100, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction Phase\n",
    "def ListOfVec1(ID) : \n",
    "    Resultlist = np.zeros((100, 128))\n",
    "    i = 0\n",
    "    for w in range(5) :\n",
    "        path = \"images/\" + \"MyPhotos/\" + str(i+1) + \".jpg\"\n",
    "        #print(path)\n",
    "        img = load_image(path)\n",
    "        img = align_image(img)\n",
    "        img = (img / 255.).astype(np.float32)\n",
    "        Resultlist[w] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "        #print(len(Resultlist))\n",
    "        i = i + 1\n",
    "    return Resultlist\n",
    "VecList1 = VecList1 + ListOfVec1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction Phase\n",
    "def ListOfVec2(ID) : \n",
    "    Resultlist = np.zeros((100, 128))\n",
    "    i = 0\n",
    "    for w in range(5,10) :\n",
    "        path = \"images/\" + \"AL-Limby/\" + str(i+1) + \".jpg\"\n",
    "        #print(path)\n",
    "        img = load_image(path)\n",
    "        img = align_image(img)\n",
    "        #img = (img / 255.).astype(np.float32)\n",
    "        Resultlist[w] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "        #print(len(Resultlist))\n",
    "        i = i + 1\n",
    "    return Resultlist\n",
    "VecList1 = VecList1 + ListOfVec2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction Phase\n",
    "def ListOfVec3(ID) : \n",
    "    Resultlist = np.zeros((100, 128))\n",
    "    i = 0\n",
    "    for w in range(10,15) :\n",
    "        path = \"images/\" + \"Colin_Powell/\" + str(i+1) + \".jpg\"\n",
    "        #print(path)\n",
    "        img = load_image(path)\n",
    "        img = align_image(img)\n",
    "        #img = (img / 255.).astype(np.float32)\n",
    "        Resultlist[w] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "        #print(len(Resultlist))\n",
    "        i = i + 1\n",
    "    return Resultlist\n",
    "VecList1 = VecList1 + ListOfVec3(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction Phase\n",
    "def ListOfVec4(ID) : \n",
    "    Resultlist = np.zeros((100, 128))\n",
    "    i = 0\n",
    "    for w in range(15,20) :\n",
    "        path = \"images/\" + \"Ahmed-Helmy/\" + str(i+1) + \".jpg\"\n",
    "        #print(path)\n",
    "        img = load_image(path)\n",
    "        img = align_image(img)\n",
    "        #img = (img / 255.).astype(np.float32)\n",
    "        Resultlist[w] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "        #print(len(Resultlist))\n",
    "        i = i + 1\n",
    "    return Resultlist\n",
    "VecList1 = VecList1 + ListOfVec4(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetNames = ['Amr Tarek','Amr Tarek','Amr Tarek','Amr Tarek','Amr Tarek','lemby','lemby','lemby','lemby','lemby','Colin','Colin','Colin','Colin','Colin','Ahmed Helmy','Ahmed Helmy','Ahmed Helmy','Ahmed Helmy','Ahmed Helmy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "targets = TargetNames\n",
    "#print(targets)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "# Numerical encoding of identities\n",
    "y = encoder.transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VecList1 = VecList1[:20]\n",
    "embedded = VecList1\n",
    "print(len(embedded))\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded[:20]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded[:20]\n",
    "\n",
    "y_train = y[:20]\n",
    "y_test = y[:20]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "svc = LinearSVC()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Veec(img) : \n",
    "    img = align_image(img)\n",
    "    #print(img)\n",
    "    img = (img / 255).astype(np.float32)\n",
    "    Resultlist = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "    return Resultlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('FaceID', frame)\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        FaceFlag = FaceOrNot(frame) \n",
    "        if FaceFlag == False :\n",
    "            cv2.putText(frame, \"No Faces\", (40, 90), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.imshow('FaceID', frame)\n",
    "        elif FaceFlag == True : \n",
    "            x = knn.predict(Veec(frame).reshape(1, -1))\n",
    "            ZzZ = encoder.inverse_transform(x)\n",
    "            print(ZzZ[0])\n",
    "            cv2.putText(frame, \"Face : \" + ZzZ[0], (40, 90), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.imshow('FaceID', frame)\n",
    "        \n",
    "    \n",
    "        if cv2.waitKey(1)%256 == 32: #Space)\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n",
      "Amr Tarek\n"
     ]
    }
   ],
   "source": [
    "Exit_flag = True\n",
    "while Exit_flag : \n",
    "    try :\n",
    "        Main()\n",
    "        Exit_flag = False\n",
    "    except :\n",
    "        Exit_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
